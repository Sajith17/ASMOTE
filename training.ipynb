{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding,Dense,LSTM,Bidirectional,Input\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.text.crf_wrapper import CRFModelWrapper\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import regex as re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GLOVE Embeddings And Tokenizor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec = {}\n",
    "with open('glove.6B/glove.6B.100d.txt','r', encoding='utf-8') as f:\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:],'float32')\n",
    "    word_to_vec[word]=vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(word_to_vec.keys())\n",
    "word_to_index = tokenizer.word_index\n",
    "index_to_word = tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 71\n",
    "vocab_size = len(word_to_index)+1\n",
    "embedding_dim = 100\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "for word, i in word_to_index.items():\n",
    "    if word in word_to_vec:\n",
    "        embedding_matrix[i] = word_to_vec[word]\n",
    "with tf.device('/CPU:0'):\n",
    "    embedding_layer = Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        weights=[embedding_matrix],\n",
    "        trainable = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3868, 2)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "def read_data(path,sentences,triplets):\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            parts = line.strip().split('#### #### ####')\n",
    "            if len(parts)==2:\n",
    "                sentence = parts[0].strip()\n",
    "                triplet = ast.literal_eval(parts[1].strip())\n",
    "\n",
    "                sentences.append(sentence)\n",
    "                triplets.append(triplet)\n",
    "sentences,triplets =[],[]\n",
    "paths = ['14res/test.txt','14res/train.txt','15res/test.txt','15res/train.txt','16res/test.txt','16res/train.txt']\n",
    "for path in paths:\n",
    "    read_data(path,sentences,triplets)\n",
    "df = pd.DataFrame({'sentence':sentences,'triplets':triplets})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2729, 2)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset='sentence',inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_sentence = []\n",
    "tokenized = []\n",
    "corrected_triplets = []\n",
    "s = 0\n",
    "for idx,row in df.iterrows():\n",
    "    tokenized_sentence = tokenizer.texts_to_sequences([row.sentence])[0]\n",
    "    regex_sentence = re.findall(r'\\b[\\'\\w]+\\b',row.sentence)\n",
    "    if len(tokenized_sentence)==len(regex_sentence):\n",
    "        triplets = row.triplets.copy()\n",
    "        new_triplets = []\n",
    "        sentence = row.sentence.split(' ')\n",
    "        for triplet in triplets:\n",
    "            #nothing-0, aspect-1, opinion-2\n",
    "            pairs = sentence.copy()\n",
    "            for j in range(len(pairs)):\n",
    "                if j in triplet[0]:\n",
    "                    pairs[j] = [pairs[j],1]\n",
    "                elif j in triplet[1]:\n",
    "                    pairs[j] = [pairs[j],2]\n",
    "                else:\n",
    "                    pairs[j] = [pairs[j],0]\n",
    "            new_pairs = []\n",
    "            for j in pairs:\n",
    "                tokenized_word = tokenizer.texts_to_sequences([j[0]])[0]\n",
    "                regex_word = re.findall(r'\\b[\\'\\w]+\\b',j[0])\n",
    "                for i in regex_word:\n",
    "                    new_pairs.append([i,j[1]])\n",
    "            aspect = []\n",
    "            opinion = []\n",
    "            for j in range(len(new_pairs)):\n",
    "                if new_pairs[j][1] == 1:\n",
    "                    aspect.append(j)\n",
    "                elif new_pairs[j][1] == 2:\n",
    "                    opinion.append(j)\n",
    "            new_triplets.append((aspect,opinion,triplet[2]))\n",
    "        new_sentence = ''\n",
    "        for i in regex_sentence:\n",
    "            new_sentence+=i+' '\n",
    "        corrected_sentence.append(new_sentence)\n",
    "        corrected_triplets.append(new_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>triplets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The bread is top notch as well</td>\n",
       "      <td>[([1], [3, 4], POS)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have to say they have one of the fastest del...</td>\n",
       "      <td>[([10, 11], [9], POS)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Food is always fresh and hot ready to eat</td>\n",
       "      <td>[([0], [3], POS), ([0], [5], POS)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did I mention that the coffee is OUTSTANDING</td>\n",
       "      <td>[([5], [7], POS)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Certainly not the best sushi in New York howev...</td>\n",
       "      <td>[([15], [18], POS)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>I have been to Rao s probably 15 times the pas...</td>\n",
       "      <td>[([4, 5], [17], POS)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>The decor is very simple but comfortable</td>\n",
       "      <td>[([1], [4], POS), ([1], [6], POS)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2709</th>\n",
       "      <td>whoever the jazz duo was they were on POINT</td>\n",
       "      <td>[([2, 3], [7, 8], POS)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>even the wine by the glass was good</td>\n",
       "      <td>[([2, 3, 4, 5], [7], POS)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>Never have I had such dramatic delivery guys a...</td>\n",
       "      <td>[([6, 7], [5], NEG)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2712 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "0                       The bread is top notch as well    \n",
       "1     I have to say they have one of the fastest del...   \n",
       "2            Food is always fresh and hot ready to eat    \n",
       "3         Did I mention that the coffee is OUTSTANDING    \n",
       "4     Certainly not the best sushi in New York howev...   \n",
       "...                                                 ...   \n",
       "2707  I have been to Rao s probably 15 times the pas...   \n",
       "2708          The decor is very simple but comfortable    \n",
       "2709       whoever the jazz duo was they were on POINT    \n",
       "2710               even the wine by the glass was good    \n",
       "2711  Never have I had such dramatic delivery guys a...   \n",
       "\n",
       "                                triplets  \n",
       "0                   [([1], [3, 4], POS)]  \n",
       "1                 [([10, 11], [9], POS)]  \n",
       "2     [([0], [3], POS), ([0], [5], POS)]  \n",
       "3                      [([5], [7], POS)]  \n",
       "4                    [([15], [18], POS)]  \n",
       "...                                  ...  \n",
       "2707               [([4, 5], [17], POS)]  \n",
       "2708  [([1], [4], POS), ([1], [6], POS)]  \n",
       "2709             [([2, 3], [7, 8], POS)]  \n",
       "2710          [([2, 3, 4, 5], [7], POS)]  \n",
       "2711                [([6, 7], [5], NEG)]  \n",
       "\n",
       "[2712 rows x 2 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'sentence':corrected_sentence,'triplets':corrected_triplets})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aspect Opinion Extraction Using CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {0:'padding',1:'O',2:'A-B',3:'A-I',4:'O-B',5:'O-I'}\n",
    "X = []\n",
    "y = []\n",
    "for idx,row in df.iterrows():\n",
    "    triplets = row.triplets\n",
    "    tokenized = pad_sequences(tokenizer.texts_to_sequences([row.sentence]),maxlen=T,padding='post')[0]\n",
    "    labelling = np.ones(shape=(T,))\n",
    "    for i in range(T):\n",
    "        if tokenized[i]==0:\n",
    "            labelling[i]=0\n",
    "    for i in triplets:\n",
    "        for j in range(len(i[0])):\n",
    "            if j == 0:\n",
    "                labelling[i[0][j]]=2\n",
    "            else:\n",
    "                labelling[i[0][j]]=3\n",
    "        for j in range(len(i[1])):\n",
    "            if j == 0:\n",
    "                labelling[i[1][j]]=4\n",
    "            else:\n",
    "                labelling[i[1][j]]=5\n",
    "    X.append(tokenized)\n",
    "    y.append(labelling)\n",
    "X = np.array(X,dtype=int)\n",
    "y = np.array(y,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRF_model(T, n_a, classes):\n",
    "    X = Input(shape=(T,))\n",
    "    embeddings = embedding_layer(X)\n",
    "    a = Bidirectional(LSTM(units=n_a,return_sequences=True, dropout=0.5, recurrent_dropout=0.4))(embeddings)\n",
    "    base_model = Model(inputs = X, outputs = a)\n",
    "    model = CRFModelWrapper(base_model, classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = CRF_model(T,64,6)\n",
    "extractor.compile(optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "68/68 [==============================] - 9s 136ms/step - accuracy: 0.7386 - loss: 2.6222 - crf_loss: 2.6222\n",
      "Epoch 2/20\n",
      "68/68 [==============================] - 9s 127ms/step - accuracy: 0.7616 - loss: 2.5919 - crf_loss: 2.5919\n",
      "Epoch 3/20\n",
      "68/68 [==============================] - 9s 128ms/step - accuracy: 0.7469 - loss: 2.5916 - crf_loss: 2.5916\n",
      "Epoch 4/20\n",
      "68/68 [==============================] - 9s 128ms/step - accuracy: 0.7603 - loss: 2.5977 - crf_loss: 2.5977\n",
      "Epoch 5/20\n",
      "68/68 [==============================] - 9s 128ms/step - accuracy: 0.7556 - loss: 2.5438 - crf_loss: 2.5438\n",
      "Epoch 6/20\n",
      "68/68 [==============================] - 9s 131ms/step - accuracy: 0.7501 - loss: 2.5632 - crf_loss: 2.5632\n",
      "Epoch 7/20\n",
      "68/68 [==============================] - 9s 127ms/step - accuracy: 0.7704 - loss: 2.5013 - crf_loss: 2.5013\n",
      "Epoch 8/20\n",
      "68/68 [==============================] - 8s 124ms/step - accuracy: 0.7649 - loss: 2.4929 - crf_loss: 2.4929\n",
      "Epoch 9/20\n",
      "68/68 [==============================] - 9s 126ms/step - accuracy: 0.7639 - loss: 2.4886 - crf_loss: 2.4886\n",
      "Epoch 10/20\n",
      "68/68 [==============================] - 9s 132ms/step - accuracy: 0.7635 - loss: 2.4720 - crf_loss: 2.4720\n",
      "Epoch 11/20\n",
      "68/68 [==============================] - 9s 131ms/step - accuracy: 0.7584 - loss: 2.4240 - crf_loss: 2.4240\n",
      "Epoch 12/20\n",
      "68/68 [==============================] - 9s 132ms/step - accuracy: 0.7649 - loss: 2.4211 - crf_loss: 2.4211\n",
      "Epoch 13/20\n",
      "68/68 [==============================] - 9s 134ms/step - accuracy: 0.7658 - loss: 2.4018 - crf_loss: 2.4018\n",
      "Epoch 14/20\n",
      "68/68 [==============================] - 9s 129ms/step - accuracy: 0.7778 - loss: 2.3858 - crf_loss: 2.3858\n",
      "Epoch 15/20\n",
      "68/68 [==============================] - 9s 132ms/step - accuracy: 0.7561 - loss: 2.4093 - crf_loss: 2.4093\n",
      "Epoch 16/20\n",
      "68/68 [==============================] - 9s 131ms/step - accuracy: 0.7704 - loss: 2.3347 - crf_loss: 2.3347\n",
      "Epoch 17/20\n",
      "68/68 [==============================] - 9s 128ms/step - accuracy: 0.7722 - loss: 2.3505 - crf_loss: 2.3505\n",
      "Epoch 18/20\n",
      "68/68 [==============================] - 9s 129ms/step - accuracy: 0.7796 - loss: 2.3580 - crf_loss: 2.3580\n",
      "Epoch 19/20\n",
      "68/68 [==============================] - 9s 130ms/step - accuracy: 0.7718 - loss: 2.3593 - crf_loss: 2.3593\n",
      "Epoch 20/20\n",
      "68/68 [==============================] - 9s 130ms/step - accuracy: 0.7704 - loss: 2.3145 - crf_loss: 2.3145\n",
      "17/17 [==============================] - 1s 45ms/step - accuracy: 0.7053 - loss: 3.7678 - crf_loss: 3.7678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7053406834602356, 4.789958477020264, 4.789958477020264]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor.fit(X_train,y_train,epochs=20)\n",
    "extractor.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 40ms/step - accuracy: 0.7053 - loss: 3.7678 - crf_loss: 3.7678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7053406834602356, 4.789958477020264, 4.789958477020264]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "affordably 4\n",
      "priced 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Affordably Priced'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    EXAMPLES = [\"Affordably Priced\"]\n",
    "    z = pad_sequences(tokenizer.texts_to_sequences(EXAMPLES),maxlen=71,padding='post')\n",
    "    aa = extractor.predict(z)\n",
    "    for i,j in zip(z[0],aa[0]):\n",
    "        if j in {2,3,4,5}:\n",
    "            print(index_to_word[i],j)\n",
    "EXAMPLES[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: extractor_model.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: extractor_model.tf\\assets\n"
     ]
    }
   ],
   "source": [
    "extractor.save('extractor_model.tf', save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aspect Opinion Pair Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair = pd.DataFrame(columns=['sentence','indices','tokenized_sentence','custom_mask','ispair'])\n",
    "for idx,row in df.iterrows():\n",
    "    sentence = row.sentence\n",
    "    tokenized = pad_sequences(tokenizer.texts_to_sequences([row.sentence]),maxlen=T,padding='post')[0]\n",
    "    aspect_i = [i[0] for i in row.triplets]\n",
    "    opinion_i = [i[1] for i in row.triplets]\n",
    "    true_pair = [tuple(i[0]+i[1]) for i in row.triplets]\n",
    "    false_pair = []\n",
    "    for i in range(len(aspect_i)):\n",
    "        for j in range(len(aspect_i)):\n",
    "            if i != j:\n",
    "                joint = tuple(aspect_i[i]+opinion_i[j])\n",
    "                if joint not in true_pair:\n",
    "                    false_pair.append(joint)\n",
    "    for i in true_pair:\n",
    "        mask = np.zeros(shape=(T,),dtype=bool)\n",
    "        for j in i:\n",
    "            mask[j]=True\n",
    "        d = pd.DataFrame({'sentence':[sentence],\n",
    "             'indices':[i],\n",
    "             'tokenized_sentence':[tokenized],\n",
    "             'custom_mask':[mask],\n",
    "             'ispair':[1]\n",
    "             })\n",
    "        df_pair = pd.concat([df_pair,d])\n",
    "    for i in false_pair:\n",
    "        mask = np.zeros(shape=(T,),dtype=bool)\n",
    "        for j in i:\n",
    "            mask[j]=True\n",
    "        d = pd.DataFrame({'sentence':[sentence],\n",
    "             'indices':[i],\n",
    "             'tokenized_sentence':[tokenized],\n",
    "             'custom_mask':[mask],\n",
    "             'ispair':[0]\n",
    "             })\n",
    "        df_pair = pd.concat([df_pair,d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>indices</th>\n",
       "      <th>tokenized_sentence</th>\n",
       "      <th>custom_mask</th>\n",
       "      <th>ispair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The bread is top notch as well</td>\n",
       "      <td>(1, 3, 4)</td>\n",
       "      <td>[202, 15739, 1409, 254, 8301, 918, 188, 0, 0, ...</td>\n",
       "      <td>[False, True, False, True, True, False, False,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have to say they have one of the fastest del...</td>\n",
       "      <td>(10, 11, 9)</td>\n",
       "      <td>[80, 4232, 138, 6115, 6102, 4232, 155, 126, 20...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food is always fresh and hot ready to eat</td>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>[1586, 1409, 6156, 4392, 190, 1321, 1105, 138,...</td>\n",
       "      <td>[True, False, False, True, False, False, False...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food is always fresh and hot ready to eat</td>\n",
       "      <td>(0, 5)</td>\n",
       "      <td>[1586, 1409, 6156, 4392, 190, 1321, 1105, 138,...</td>\n",
       "      <td>[True, False, False, False, False, True, False...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Did I mention that the coffee is OUTSTANDING</td>\n",
       "      <td>(5, 7)</td>\n",
       "      <td>[13550, 80, 14722, 6099, 202, 4567, 1409, 1456...</td>\n",
       "      <td>[False, False, False, False, False, True, Fals...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      indices  \\\n",
       "0                    The bread is top notch as well     (1, 3, 4)   \n",
       "0  I have to say they have one of the fastest del...  (10, 11, 9)   \n",
       "0         Food is always fresh and hot ready to eat        (0, 3)   \n",
       "0         Food is always fresh and hot ready to eat        (0, 5)   \n",
       "0      Did I mention that the coffee is OUTSTANDING        (5, 7)   \n",
       "\n",
       "                                  tokenized_sentence  \\\n",
       "0  [202, 15739, 1409, 254, 8301, 918, 188, 0, 0, ...   \n",
       "0  [80, 4232, 138, 6115, 6102, 4232, 155, 126, 20...   \n",
       "0  [1586, 1409, 6156, 4392, 190, 1321, 1105, 138,...   \n",
       "0  [1586, 1409, 6156, 4392, 190, 1321, 1105, 138,...   \n",
       "0  [13550, 80, 14722, 6099, 202, 4567, 1409, 1456...   \n",
       "\n",
       "                                         custom_mask ispair  \n",
       "0  [False, True, False, True, True, False, False,...      1  \n",
       "0  [False, False, False, False, False, False, Fal...      1  \n",
       "0  [True, False, False, True, False, False, False...      1  \n",
       "0  [True, False, False, False, False, True, False...      1  \n",
       "0  [False, False, False, False, False, True, Fals...      1  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair_train,df_pair_test = train_test_split(df_pair,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count_1,class_count_0 = df_pair_train.ispair.value_counts()\n",
    "df_pair_train_class_0 = df_pair_train[df_pair_train.ispair == 0]\n",
    "df_pair_train_class_1 = df_pair_train[df_pair_train.ispair == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ispair\n",
       "1    3626\n",
       "0    2777\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair_train.ispair.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair_train_class_0_over = df_pair_train_class_0.sample(class_count_1,replace=True)\n",
    "df_pair_train_over = pd.concat([df_pair_train_class_1,df_pair_train_class_0_over])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ispair\n",
       "1    3626\n",
       "0    3626\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair_train_over.ispair.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized = np.array([x for x in df_pair_train_over.tokenized_sentence],dtype=int)\n",
    "X_test_tokenized = np.array([x for x in df_pair_test.tokenized_sentence],dtype=int)\n",
    "X_train_mask = np.array([x for x in df_pair_train_over.custom_mask],dtype=bool)\n",
    "X_test_mask = np.array([x for x in df_pair_test.custom_mask],dtype=bool)\n",
    "y_train = np.array([x for x in df_pair_train_over.ispair],dtype=int)\n",
    "y_test = np.array([x for x in df_pair_test.ispair],dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_classification_model(units):\n",
    "    input1 = Input(shape=(71,))\n",
    "    input2 = Input(shape=(71,),dtype=tf.bool)\n",
    "    embeddings = embedding_layer(input1)\n",
    "    x = Bidirectional(LSTM(units,return_sequences=True,dropout=0.5))(embeddings)\n",
    "    x = LSTM(units)(x,mask=input2)\n",
    "    outputs = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model([input1,input2],outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pair_classification_model(32)\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "227/227 [==============================] - 17s 52ms/step - loss: 0.6078 - accuracy: 0.6569\n",
      "Epoch 2/20\n",
      "227/227 [==============================] - 14s 62ms/step - loss: 0.4346 - accuracy: 0.8053\n",
      "Epoch 3/20\n",
      "227/227 [==============================] - 14s 62ms/step - loss: 0.3639 - accuracy: 0.8438\n",
      "Epoch 4/20\n",
      "227/227 [==============================] - 14s 62ms/step - loss: 0.3288 - accuracy: 0.8610\n",
      "Epoch 5/20\n",
      "227/227 [==============================] - 14s 62ms/step - loss: 0.3056 - accuracy: 0.8722\n",
      "Epoch 6/20\n",
      "227/227 [==============================] - 14s 63ms/step - loss: 0.2740 - accuracy: 0.8864\n",
      "Epoch 7/20\n",
      "227/227 [==============================] - 15s 64ms/step - loss: 0.2534 - accuracy: 0.8966\n",
      "Epoch 8/20\n",
      "227/227 [==============================] - 14s 61ms/step - loss: 0.2413 - accuracy: 0.9026\n",
      "Epoch 9/20\n",
      "227/227 [==============================] - 7s 31ms/step - loss: 0.2204 - accuracy: 0.9120\n",
      "Epoch 10/20\n",
      "227/227 [==============================] - 7s 31ms/step - loss: 0.2088 - accuracy: 0.9163\n",
      "Epoch 11/20\n",
      "227/227 [==============================] - 7s 32ms/step - loss: 0.2036 - accuracy: 0.9222\n",
      "Epoch 12/20\n",
      "227/227 [==============================] - 7s 32ms/step - loss: 0.1981 - accuracy: 0.9247\n",
      "Epoch 13/20\n",
      "227/227 [==============================] - 8s 36ms/step - loss: 0.1759 - accuracy: 0.9331\n",
      "Epoch 14/20\n",
      "227/227 [==============================] - 7s 30ms/step - loss: 0.1648 - accuracy: 0.9377\n",
      "Epoch 15/20\n",
      "227/227 [==============================] - 8s 35ms/step - loss: 0.1614 - accuracy: 0.9382\n",
      "Epoch 16/20\n",
      "227/227 [==============================] - 13s 59ms/step - loss: 0.1499 - accuracy: 0.9439\n",
      "Epoch 17/20\n",
      "227/227 [==============================] - 13s 59ms/step - loss: 0.1534 - accuracy: 0.9404\n",
      "Epoch 18/20\n",
      "227/227 [==============================] - 14s 62ms/step - loss: 0.1392 - accuracy: 0.9458\n",
      "Epoch 19/20\n",
      "227/227 [==============================] - 13s 59ms/step - loss: 0.1333 - accuracy: 0.9495\n",
      "Epoch 20/20\n",
      "227/227 [==============================] - 7s 29ms/step - loss: 0.1285 - accuracy: 0.9516\n",
      "67/67 [==============================] - 3s 11ms/step - loss: 0.2444 - accuracy: 0.9152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24444632232189178, 0.9152224659919739]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train_tokenized,X_train_mask],y_train,epochs=20)\n",
    "model.evaluate([X_test_tokenized,X_test_mask],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 2s 12ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91       946\n",
      "           1       0.95      0.90      0.92      1189\n",
      "\n",
      "    accuracy                           0.92      2135\n",
      "   macro avg       0.91      0.92      0.91      2135\n",
      "weighted avg       0.92      0.92      0.92      2135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict([X_test_tokenized,X_test_mask])\n",
    "y_pred = np.squeeze((y_pred > 0.5).astype(int))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajit\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('pair_classifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polarity Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_polarity = {0:'NEG',1:'NEU',2:'POS'}\n",
    "polarity_to_index = {'NEG':0,'NEU':1,'POS':2}\n",
    "df_polarity = pd.DataFrame(columns=['sentence','tokenized_sentence','polarity'])\n",
    "df_polarity\n",
    "for idx,row in df.iterrows():\n",
    "    sentence = row.sentence.split(' ')\n",
    "    for triplet in row.triplets:\n",
    "        filtered_sent = ''\n",
    "        for i in triplet[0]+triplet[1]:\n",
    "            filtered_sent+=sentence[i]+' '\n",
    "        tokenized = pad_sequences(tokenizer.texts_to_sequences([filtered_sent]),maxlen=25,padding='post')[0]\n",
    "        d = pd.DataFrame({'sentence':[filtered_sent],'tokenized_sentence':[tokenized],'polarity':[polarity_to_index[triplet[2]]]})\n",
    "        df_polarity = pd.concat([df_polarity,d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokenized_sentence</th>\n",
       "      <th>mask</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The bread is top notch as well</td>\n",
       "      <td>[202, 15739, 1409, 254, 8301, 918, 188, 0, 0, ...</td>\n",
       "      <td>[False, True, False, True, True, False, False,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have to say they have one of the fastest del...</td>\n",
       "      <td>[80, 4232, 138, 6115, 6102, 4232, 155, 126, 20...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food is always fresh and hot ready to eat</td>\n",
       "      <td>[1586, 1409, 6156, 4392, 190, 1321, 1105, 138,...</td>\n",
       "      <td>[True, False, False, True, False, False, False...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food is always fresh and hot ready to eat</td>\n",
       "      <td>[1586, 1409, 6156, 4392, 190, 1321, 1105, 138,...</td>\n",
       "      <td>[True, False, False, False, False, True, False...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Did I mention that the coffee is OUTSTANDING</td>\n",
       "      <td>[13550, 80, 14722, 6099, 202, 4567, 1409, 1456...</td>\n",
       "      <td>[False, False, False, False, False, True, Fals...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The decor is very simple but comfortable</td>\n",
       "      <td>[202, 27879, 1409, 13562, 6362, 13534, 14804, ...</td>\n",
       "      <td>[False, True, False, False, True, False, False...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The decor is very simple but comfortable</td>\n",
       "      <td>[202, 27879, 1409, 13562, 6362, 13534, 14804, ...</td>\n",
       "      <td>[False, True, False, False, False, False, True...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>whoever the jazz duo was they were on POINT</td>\n",
       "      <td>[18072, 202, 1344, 4855, 4231, 6102, 3370, 152...</td>\n",
       "      <td>[False, False, True, True, False, False, False...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>even the wine by the glass was good</td>\n",
       "      <td>[1993, 202, 2957, 253, 202, 1033, 4231, 811, 0...</td>\n",
       "      <td>[False, False, True, True, True, True, False, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Never have I had such dramatic delivery guys a...</td>\n",
       "      <td>[1769, 4232, 80, 13535, 13551, 14508, 6475, 14...</td>\n",
       "      <td>[False, False, False, False, False, True, True...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4815 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  \\\n",
       "0                     The bread is top notch as well    \n",
       "0   I have to say they have one of the fastest del...   \n",
       "0          Food is always fresh and hot ready to eat    \n",
       "0          Food is always fresh and hot ready to eat    \n",
       "0       Did I mention that the coffee is OUTSTANDING    \n",
       "..                                                ...   \n",
       "0           The decor is very simple but comfortable    \n",
       "0           The decor is very simple but comfortable    \n",
       "0        whoever the jazz duo was they were on POINT    \n",
       "0                even the wine by the glass was good    \n",
       "0   Never have I had such dramatic delivery guys a...   \n",
       "\n",
       "                                   tokenized_sentence  \\\n",
       "0   [202, 15739, 1409, 254, 8301, 918, 188, 0, 0, ...   \n",
       "0   [80, 4232, 138, 6115, 6102, 4232, 155, 126, 20...   \n",
       "0   [1586, 1409, 6156, 4392, 190, 1321, 1105, 138,...   \n",
       "0   [1586, 1409, 6156, 4392, 190, 1321, 1105, 138,...   \n",
       "0   [13550, 80, 14722, 6099, 202, 4567, 1409, 1456...   \n",
       "..                                                ...   \n",
       "0   [202, 27879, 1409, 13562, 6362, 13534, 14804, ...   \n",
       "0   [202, 27879, 1409, 13562, 6362, 13534, 14804, ...   \n",
       "0   [18072, 202, 1344, 4855, 4231, 6102, 3370, 152...   \n",
       "0   [1993, 202, 2957, 253, 202, 1033, 4231, 811, 0...   \n",
       "0   [1769, 4232, 80, 13535, 13551, 14508, 6475, 14...   \n",
       "\n",
       "                                                 mask polarity  \n",
       "0   [False, True, False, True, True, False, False,...        2  \n",
       "0   [False, False, False, False, False, False, Fal...        2  \n",
       "0   [True, False, False, True, False, False, False...        2  \n",
       "0   [True, False, False, False, False, True, False...        2  \n",
       "0   [False, False, False, False, False, True, Fals...        2  \n",
       "..                                                ...      ...  \n",
       "0   [False, True, False, False, True, False, False...        2  \n",
       "0   [False, True, False, False, False, False, True...        2  \n",
       "0   [False, False, True, True, False, False, False...        2  \n",
       "0   [False, False, True, True, True, True, False, ...        2  \n",
       "0   [False, False, False, False, False, True, True...        0  \n",
       "\n",
       "[4815 rows x 4 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polarity_train,df_polarity_test = train_test_split(df_polarity,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count_2,class_count_0,class_count_1 = df_polarity_train.polarity.value_counts()\n",
    "df_polarity_train_class_0 = df_polarity_train[df_polarity_train.polarity == 0]\n",
    "df_polarity_train_class_1 = df_polarity_train[df_polarity_train.polarity == 1]\n",
    "df_polarity_train_class_2 = df_polarity_train[df_polarity_train.polarity == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(710, 222, 2679)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_count_0,class_count_1,class_count_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polarity_train_class_0_over = df_polarity_train_class_0.sample(class_count_2,replace=True)\n",
    "df_polarity_train_class_1_over = df_polarity_train_class_1.sample(class_count_2,replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8037, 3)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polarity_train_under = pd.concat([df_polarity_train_class_0_over,df_polarity_train_class_1_over,df_polarity_train_class_2],axis=0)\n",
    "df_polarity_train_under.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([x for x in df_polarity_train_under.tokenized_sentence],dtype=int)\n",
    "X_test = np.array([x for x in df_polarity_test.tokenized_sentence],dtype=int)\n",
    "y_train = np.array(df_polarity_train_under.polarity,dtype=int)\n",
    "y_test = np.array(df_polarity_test.polarity,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8037, 25), (1204, 25), (8037,), (1204,))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_classifier(units):\n",
    "    input = Input(shape=(25,))\n",
    "    x = embedding_layer(input)\n",
    "    x = LSTM(units, dropout=0.4, recurrent_dropout=0.4)(x)\n",
    "    output = Dense(3,activation='softmax')(x)\n",
    "    return Model(input,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = polarity_classifier(32)\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "252/252 [==============================] - 5s 10ms/step - loss: 0.9515 - accuracy: 0.5378\n",
      "Epoch 2/40\n",
      "252/252 [==============================] - 3s 12ms/step - loss: 0.7947 - accuracy: 0.6688\n",
      "Epoch 3/40\n",
      "252/252 [==============================] - 5s 20ms/step - loss: 0.7332 - accuracy: 0.7006\n",
      "Epoch 4/40\n",
      "252/252 [==============================] - 5s 20ms/step - loss: 0.6852 - accuracy: 0.7235\n",
      "Epoch 5/40\n",
      "252/252 [==============================] - 5s 20ms/step - loss: 0.6309 - accuracy: 0.7555\n",
      "Epoch 6/40\n",
      "252/252 [==============================] - 5s 20ms/step - loss: 0.6027 - accuracy: 0.7727\n",
      "Epoch 7/40\n",
      "252/252 [==============================] - 5s 20ms/step - loss: 0.5698 - accuracy: 0.7859\n",
      "Epoch 8/40\n",
      "252/252 [==============================] - 5s 20ms/step - loss: 0.5608 - accuracy: 0.7908\n",
      "Epoch 9/40\n",
      "252/252 [==============================] - 3s 12ms/step - loss: 0.5328 - accuracy: 0.8008\n",
      "Epoch 10/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.5120 - accuracy: 0.8105\n",
      "Epoch 11/40\n",
      "252/252 [==============================] - 3s 10ms/step - loss: 0.4906 - accuracy: 0.8217\n",
      "Epoch 12/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.4815 - accuracy: 0.8218\n",
      "Epoch 13/40\n",
      "252/252 [==============================] - 4s 14ms/step - loss: 0.4704 - accuracy: 0.8273\n",
      "Epoch 14/40\n",
      "252/252 [==============================] - 5s 20ms/step - loss: 0.4517 - accuracy: 0.8319\n",
      "Epoch 15/40\n",
      "252/252 [==============================] - 3s 10ms/step - loss: 0.4409 - accuracy: 0.8407\n",
      "Epoch 16/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.4425 - accuracy: 0.8341\n",
      "Epoch 17/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.4315 - accuracy: 0.8452\n",
      "Epoch 18/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.4222 - accuracy: 0.8461\n",
      "Epoch 19/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.4087 - accuracy: 0.8522\n",
      "Epoch 20/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.4092 - accuracy: 0.8529\n",
      "Epoch 21/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.3897 - accuracy: 0.8572\n",
      "Epoch 22/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.3811 - accuracy: 0.8680\n",
      "Epoch 23/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.3806 - accuracy: 0.8609\n",
      "Epoch 24/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.3816 - accuracy: 0.8635\n",
      "Epoch 25/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.3723 - accuracy: 0.8659\n",
      "Epoch 26/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.3669 - accuracy: 0.8662\n",
      "Epoch 27/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.3648 - accuracy: 0.8681\n",
      "Epoch 28/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.3533 - accuracy: 0.8756\n",
      "Epoch 29/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.3514 - accuracy: 0.8781\n",
      "Epoch 30/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.3487 - accuracy: 0.8746\n",
      "Epoch 31/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.3427 - accuracy: 0.8733\n",
      "Epoch 32/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.3548 - accuracy: 0.8708\n",
      "Epoch 33/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.3396 - accuracy: 0.8815\n",
      "Epoch 34/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.3468 - accuracy: 0.8771\n",
      "Epoch 35/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.3357 - accuracy: 0.8803\n",
      "Epoch 36/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.3267 - accuracy: 0.8844\n",
      "Epoch 37/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.3305 - accuracy: 0.8833\n",
      "Epoch 38/40\n",
      "252/252 [==============================] - 3s 10ms/step - loss: 0.3251 - accuracy: 0.8853\n",
      "Epoch 39/40\n",
      "252/252 [==============================] - 3s 10ms/step - loss: 0.3244 - accuracy: 0.8860\n",
      "Epoch 40/40\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 0.3144 - accuracy: 0.8880\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5996 - accuracy: 0.8239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5995977520942688, 0.8239202499389648]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=40)\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.72       241\n",
      "           1       0.35      0.57      0.43        80\n",
      "           2       0.92      0.88      0.90       883\n",
      "\n",
      "    accuracy                           0.82      1204\n",
      "   macro avg       0.67      0.72      0.68      1204\n",
      "weighted avg       0.85      0.82      0.83      1204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = [np.argmax(x) for x in y_pred]\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('polarity_classifier.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = 71\n",
    "T2 = 25\n",
    "with open('tokenizer.pickle', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "extractor = tf.keras.models.load_model('extractor_model.tf')\n",
    "pair_classfier = tf.keras.models.load_model('pair_classifier.h5')\n",
    "polarity_classifier = tf.keras.models.load_model('polarity_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_33 (InputLayer)       [(None, 71)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 71, 100)              3392530   ['input_33[0][0]']            \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " bidirectional_16 (Bidirect  (None, 71, 64)               34048     ['embedding[0][0]']           \n",
      " ional)                                                                                           \n",
      "                                                                                                  \n",
      " input_34 (InputLayer)       [(None, 71)]                 0         []                            \n",
      "                                                                                                  \n",
      " lstm_33 (LSTM)              (None, 32)                   12416     ['bidirectional_16[0][0]',    \n",
      "                                                                     'input_34[0][0]']            \n",
      "                                                                                                  \n",
      " dense_17 (Dense)            (None, 1)                    33        ['lstm_33[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 33971797 (129.59 MB)\n",
      "Trainable params: 46497 (181.63 KB)\n",
      "Non-trainable params: 33925300 (129.41 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pair_classfier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>triplets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The bread is top notch as well</td>\n",
       "      <td>[([1], [3, 4], POS)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have to say they have one of the fastest del...</td>\n",
       "      <td>[([10, 11], [9], POS)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Food is always fresh and hot ready to eat</td>\n",
       "      <td>[([0], [3], POS), ([0], [5], POS)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did I mention that the coffee is OUTSTANDING</td>\n",
       "      <td>[([5], [7], POS)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Certainly not the best sushi in New York howev...</td>\n",
       "      <td>[([15], [18], POS)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I trust the people at Go Sushi it never disapp...</td>\n",
       "      <td>[([3], [1], POS)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Straight forward no surprises very decent Japa...</td>\n",
       "      <td>[([6, 7], [5], POS)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BEST spicy tuna roll great asian salad</td>\n",
       "      <td>[([5, 6], [4], POS), ([1, 2, 3], [0], POS)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Try the rose roll not on menu</td>\n",
       "      <td>[([2, 3], [0], POS)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I love the drinks esp lychee martini and the f...</td>\n",
       "      <td>[([3], [1], POS), ([5, 6], [1], POS), ([9], [1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0                    The bread is top notch as well    \n",
       "1  I have to say they have one of the fastest del...   \n",
       "2         Food is always fresh and hot ready to eat    \n",
       "3      Did I mention that the coffee is OUTSTANDING    \n",
       "4  Certainly not the best sushi in New York howev...   \n",
       "5  I trust the people at Go Sushi it never disapp...   \n",
       "6  Straight forward no surprises very decent Japa...   \n",
       "7            BEST spicy tuna roll great asian salad    \n",
       "8                     Try the rose roll not on menu    \n",
       "9  I love the drinks esp lychee martini and the f...   \n",
       "\n",
       "                                            triplets  \n",
       "0                               [([1], [3, 4], POS)]  \n",
       "1                             [([10, 11], [9], POS)]  \n",
       "2                 [([0], [3], POS), ([0], [5], POS)]  \n",
       "3                                  [([5], [7], POS)]  \n",
       "4                                [([15], [18], POS)]  \n",
       "5                                  [([3], [1], POS)]  \n",
       "6                               [([6, 7], [5], POS)]  \n",
       "7        [([5, 6], [4], POS), ([1, 2, 3], [0], POS)]  \n",
       "8                               [([2, 3], [0], POS)]  \n",
       "9  [([3], [1], POS), ([5, 6], [1], POS), ([9], [1...  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_triplets(sentence):\n",
    "    sentences = sentence.split('.')\n",
    "    sentences = [i for i in sentences if i]\n",
    "    regex_sentence = [re.findall(r'\\b[\\'\\w]+\\b',i) for i in sentences]\n",
    "    tokenized = pad_sequences(tokenizer.texts_to_sequences(np.array(sentences)),maxlen=T1,padding='post')\n",
    "    labels = extractor.predict(tokenized)\n",
    "    pair_sent = []\n",
    "    mask = []\n",
    "    aspects = []\n",
    "    opinions = []\n",
    "    aspects_i = []\n",
    "    opinions_i = []\n",
    "    for i in range(len(labels)):\n",
    "        aspect_indices = []\n",
    "        opinion_indices = []\n",
    "        current_aspect_index = []\n",
    "        current_opinion_index = []\n",
    "        aspect = []\n",
    "        opinion = []\n",
    "        current_aspect = ''\n",
    "        current_opinion = ''\n",
    "        for j in range(len(labels[0])):\n",
    "            if labels[i][j] == 2:\n",
    "                if current_aspect_index:\n",
    "                    aspect_indices.append(current_aspect_index)\n",
    "                    aspect.append(current_aspect)\n",
    "                current_aspect_index = [j]\n",
    "                current_aspect = regex_sentence[i][j]+' '\n",
    "            elif labels[i][j] == 3:\n",
    "                current_aspect_index.append(j)\n",
    "                current_aspect+=regex_sentence[i][j]+' '\n",
    "            elif labels[i][j] == 4:\n",
    "                if current_opinion_index:\n",
    "                    opinion_indices.append(current_opinion_index)\n",
    "                    opinion.append(current_opinion)\n",
    "                current_opinion_index = [j]\n",
    "                current_opinion = regex_sentence[i][j]+' '\n",
    "            elif labels[i][j] == 5:\n",
    "                current_opinion_index.append(j)\n",
    "                current_opinion+=regex_sentence[i][j]+' '\n",
    "        if current_aspect_index:\n",
    "            aspect_indices.append(current_aspect_index)\n",
    "            aspect.append(current_aspect)\n",
    "        if current_opinion_index:\n",
    "            opinion_indices.append(current_opinion_index)\n",
    "            opinion.append(current_opinion)\n",
    "        for x in range(len(aspect_indices)):\n",
    "            for y in range(len(opinion_indices)):\n",
    "                pair_sent.append(tokenized[i])\n",
    "                m = np.zeros(shape=(T1),dtype=bool)\n",
    "                m[aspect_indices[x]+opinion_indices[y]] = True\n",
    "                mask.append(m)\n",
    "                aspects_i.append(aspect_indices[x])\n",
    "                opinions_i.append(opinion_indices[y])\n",
    "                aspects.append(aspect[x])\n",
    "                opinions.append(opinion[y])\n",
    "    pair_sent = np.array(pair_sent,dtype=int)\n",
    "    mask = np.array(mask,dtype=bool)\n",
    "    pair_pred = pair_classfier.predict([pair_sent,mask])\n",
    "    aspects_i = [aspects_i[x] for x in range(len(aspects_i)) if pair_pred[x][0]>=0.5] \n",
    "    opinions_i = [opinions_i[x] for x in range(len(opinions_i)) if pair_pred[x][0]>=0.5]\n",
    "    aspects =  [aspects[x] for x in range(len(aspects)) if pair_pred[x][0]>=0.5]\n",
    "    opinions = [opinions[x] for x in range(len(opinions)) if pair_pred[x][0]>=0.5]\n",
    "    sentences = [x+y for x,y in zip(aspects,opinions)]\n",
    "    tokenized_sentence = pad_sequences(tokenizer.texts_to_sequences(np.array(sentences)),maxlen=T2,padding='post')\n",
    "    y_pred = polarity_classifier.predict(tokenized_sentence)\n",
    "    y_pred = [np.argmax(x) for x in y_pred]\n",
    "    triplets = []\n",
    "    for i in range(len(y_pred)):\n",
    "        sentiment = 'NEG'\n",
    "        if y_pred[i]==1:\n",
    "            sentiment = 'NEU'\n",
    "        elif y_pred[i]==2:\n",
    "            sentiment = \"POS\"\n",
    "        triplets.append((aspects[i],opinions[i],sentiment))\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('terrace ', 'pretty ', 'NEU'),\n",
       " ('terrace ', 'private ', 'POS'),\n",
       " ('waitress ', 'wonderful ', 'POS'),\n",
       " ('food ', 'delicious ', 'POS')]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_triplets('We sat outside on the terrace which was very pretty and private. Our waitress was wonderful and the food was absolutely delicious!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
